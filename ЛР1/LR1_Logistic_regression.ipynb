{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder, 'y_train.npy'))    \n",
    "    x_test = np.load(os.path.join(folder, 'x_test.npy'))    \n",
    "    y_test = np.load(os.path.join(folder, 'y_test.npy'))    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        rng = np.random.default_rng(seed=0)\n",
    "        self.w = rng.normal(size=(dim, 1)) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "        \n",
    "    def predict(self, x, probs=False):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        assert x.shape[1] == self.w.shape[0], \\\n",
    "            \"Размерность экземпляров данных не соответствует ожидаемой: \" + \\\n",
    "            f\"ожидалось x.shape[1]={self.w.shape[0]}, но было получено x.shape[1]={x.shape[1]}\"\n",
    "        \n",
    "        x = x.dot(self.w) + self.b  # logits\n",
    "        p = sigmoid(x)  # probabilities\n",
    "        if probs:\n",
    "            return p\n",
    "        return np.array(p > 0.5).astype('int32')\n",
    "        \n",
    "    def fit(self, x, y, iters=1000, lr=0.01):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        # y - np.array размернсоти [N]\n",
    "        #     Массив меток (правильных ответов).\n",
    "        assert len(x) == len(y), \\\n",
    "            \"Количество экземпляров в массиве X не равно количеству меток в массиве Y. \" + \\\n",
    "            f\"Полученные размеры: len(X) = {len(x)}, len(Y) = {len(y)}.\"\n",
    "        assert x.shape[1] == self.w.shape[0], \\\n",
    "            \"Размерность экземпляров данных не соответствует ожидаемой: \" + \\\n",
    "            f\"ожидалось x.shape[1]={self.w.shape[0]}, но было получено x.shape[1]={x.shape[1]}\"\n",
    "        # Алгоритм градиентного спуска.\n",
    "        # Минимизируется бинарная кросс-энтропия.\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Применение логистической регрессии (несбалансированные данные)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Создание и обучение логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "# Указание: производить нормализацию данных не нужно, это часть задания.\n",
    "x_train, y_train, x_test, y_test = load_data('dataset1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x28c519f8850>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте модель логистической регрессии и обучите её, используя метод fit.\n",
    "\n",
    "\n",
    "# Создание модели логистической регрессии\n",
    "model = LogisticRegression(dim=x_train.shape[1])\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9045454545454545\n"
     ]
    }
   ],
   "source": [
    "# Получите предсказания на тестовой выборке и оцените точность модели, \n",
    "# используя accuracy_score из пакета SciKit-Learn.\n",
    "# Получение предсказаний на тестовой выборке\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Оценка точности модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Анализ качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, brother!\n"
     ]
    }
   ],
   "source": [
    "# Допишите класс \"глупого классификатора\", что всегда предсказывает класс `0`. \n",
    "\n",
    "class DummyClassifier:\n",
    "    def __init__(self):\n",
    "        print('Hello, brother!')\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # Всегда предсказывает класс 0\n",
    "        return np.zeros(x.shape[0], dtype=int)\n",
    "    \n",
    "dummy_classifier = DummyClassifier()\n",
    "y_dummy_pred = dummy_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier Accuracy: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Оцените точность \"глупого классификатора\", объясните результат.\n",
    "dummy_accuracy = accuracy_score(y_test, y_dummy_pred)\n",
    "print(f'Dummy Classifier Accuracy: {dummy_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Глупый классификатор\" всегда предсказывает класс 0, поэтому его точность будет зависеть от того, сколько экземпляров класса 0 в тестовом наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lubus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Используйте дополнительные метрики (f1-score, recall, precision) из пакета sklearn для анализа \"глупого классификатора\".\n",
    "dummy_f1 = f1_score(y_test, y_dummy_pred, average='binary')\n",
    "dummy_recall = recall_score(y_test, y_dummy_pred, average='binary')\n",
    "dummy_precision = precision_score(y_test, y_dummy_pred, average='binary')\n",
    "\n",
    "print(f'Dummy Classifier f1: {dummy_f1}')\n",
    "print(f'Dummy Classifier recall: {dummy_recall}')\n",
    "print(f'Dummy Classifier precision: {dummy_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используя те же метрики, проанализируйте обученную вами модель логистической регрессии.\n",
    "model_f1 = f1_score(y_test, y_pred, average='binary')\n",
    "model_recall = recall_score(y_test, y_pred, average='binary')\n",
    "model_precision = precision_score(y_test, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объясните результат, описав его комментариями в этой клетке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия, обученная на несбалансированных данных, может давать хорошие результаты по метрике точности, но метрики F1, Recall и Precision могут показать проблемы с классификацией менее представленных классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Анализ набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set: {0.0: 200, 1.0: 20}\n"
     ]
    }
   ],
   "source": [
    "# Посчитайте количество экземпляров данных для каждого класса.\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"Class distribution in training set: {dict(zip(unique, counts))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предложите способ улучшения качества модели. Подсказка: добавление дубликатов в данные.\n",
    "# Указание: не изменяйте тестовую выборку.\n",
    "\n",
    "# Увеличение данных для класса с меньшим количеством экземпляров\n",
    "class_0_count = counts[0]\n",
    "class_1_count = counts[1]\n",
    "\n",
    "# Если класс 1 меньше, увеличим его до класса 0\n",
    "if class_1_count < class_0_count:\n",
    "    diff = class_0_count - class_1_count\n",
    "    indices_class_1 = np.where(y_train == 1)[0]\n",
    "    x_train_upsampled = np.vstack([x_train, x_train[indices_class_1][:diff]])\n",
    "    y_train_upsampled = np.hstack([y_train, y_train[indices_class_1][:diff]])\n",
    "else:\n",
    "    x_train_upsampled = x_train\n",
    "    y_train_upsampled = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x28c508129d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте и обучите модель с использованием предложенных наработок.\n",
    "model_balanced = LogisticRegression(dim=x_train.shape[1])\n",
    "model_balanced.fit(x_train_upsampled, y_train_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Model Accuracy: 0.9136363636363637\n",
      "Balanced Model F1 Score: 0.4864864864864865\n",
      "Balanced Model Recall: 0.45\n",
      "Balanced Model Precision: 0.5294117647058824\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics. \n",
    "# Указание: постарайтесь сбалансировать данные таким образом, чтобы новая модель была ощутимо лучше старой.\n",
    "\n",
    "y_pred_balanced = model_balanced.predict(x_test)\n",
    "\n",
    "# Оценка метрик для новой модели\n",
    "balanced_accuracy = accuracy_score(y_test, y_pred_balanced)\n",
    "balanced_f1 = f1_score(y_test, y_pred_balanced, average='binary')\n",
    "balanced_recall = recall_score(y_test, y_pred_balanced, average='binary')\n",
    "balanced_precision = precision_score(y_test, y_pred_balanced, average='binary')\n",
    "\n",
    "print(f'Balanced Model Accuracy: {balanced_accuracy}')\n",
    "print(f'Balanced Model F1 Score: {balanced_f1}')\n",
    "print(f'Balanced Model Recall: {balanced_recall}')\n",
    "print(f'Balanced Model Precision: {balanced_precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном решении мы сделали данные более сбалансированными, что привело к улучшению метрик для класса с меньшим количеством примеров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Применение логистической регрессии (нелинейные данные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x28c33110f50>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте и обучите модель но этом наборе данных.\n",
    "model = LogisticRegression(dim=x_train.shape[1])\n",
    "\n",
    "# Обучение модели на исходных данных\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model Accuracy: 0.57\n",
      "Initial Model F1 Score: 0.6194690265486725\n",
      "Initial Model Recall: 0.7777777777777778\n",
      "Initial Model Precision: 0.5147058823529411\n"
     ]
    }
   ],
   "source": [
    "# Получение предсказаний на тестовой выборке\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Оценка качества модели\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(f'Initial Model Accuracy: {accuracy}')\n",
    "print(f'Initial Model F1 Score: {f1}')\n",
    "print(f'Initial Model Recall: {recall}')\n",
    "print(f'Initial Model Precision: {precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначальная модель показывает базовые результаты на нелинейных данных. В таких случаях линейная модель может не справляться с задачей классификации, так как границы между классами могут быть сложными и нелинейными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING: попробуйте применить на исходных данных разные нелинейные функции (sin, tanh, ...).\n",
    "# Объедините трансформированные данные с исходными (важно: количество экземпляров в x_train не должно увеличиться).\n",
    "# Применение нелинейных функций на данных\n",
    "x_train_sin = np.sin(x_train)\n",
    "x_train_tanh = np.tanh(x_train)\n",
    "\n",
    "x_test_sin = np.sin(x_test)\n",
    "x_test_tanh = np.tanh(x_test)\n",
    "\n",
    "# Объединение оригинальных и трансформированных данных\n",
    "x_train_augmented = np.hstack((x_train, x_train_sin, x_train_tanh))\n",
    "x_test_augmented = np.hstack((x_test, x_test_sin, x_test_tanh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель с использованием наработок.\n",
    "# Обучение новой модели на расширенных данных\n",
    "model_augmented = LogisticRegression(dim=x_train_augmented.shape[1])\n",
    "\n",
    "model_augmented.fit(x_train_augmented, y_train, iters=5000, lr=0.001)\n",
    "\n",
    "# Получение предсказаний на расширенной тестовой выборке\n",
    "y_pred_augmented = model_augmented.predict(x_test_augmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Model Accuracy: 0.86\n",
      "Augmented Model F1 Score: 0.8157894736842105\n",
      "Augmented Model Recall: 0.6888888888888889\n",
      "Augmented Model Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics. \n",
    "# Указание: постарайтесь добиться точности в 100%!\n",
    "# Оценка новой модели\n",
    "augmented_accuracy = accuracy_score(y_test, y_pred_augmented)\n",
    "augmented_f1 = f1_score(y_test, y_pred_augmented, average='binary')\n",
    "augmented_recall = recall_score(y_test, y_pred_augmented, average='binary')\n",
    "augmented_precision = precision_score(y_test, y_pred_augmented, average='binary')\n",
    "\n",
    "print(f'Augmented Model Accuracy: {augmented_accuracy}')\n",
    "print(f'Augmented Model F1 Score: {augmented_f1}')\n",
    "print(f'Augmented Model Recall: {augmented_recall}')\n",
    "print(f'Augmented Model Precision: {augmented_precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering с использованием нелинейных функций (таких как sin и tanh) помогает добавлять новые признаки, которые позволяют модели лучше разделять данные. Это может улучшить качество классификации.\n",
    "\n",
    "По сравнению с исходной моделью, модель с расширенными данными должна показать лучшее качество на тестовом наборе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Доп. задания (любое на выбор, опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 'Упрощение' логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложность: легко."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Модифицируйте класс логистической регрессии так, чтобы в нём не использовалась сигмоида.\n",
    "То есть вывод о предсказанном классе должен делаться на основе значений \"до сигмоиды\".\n",
    "Вспомогательная ссылка: https://en.wikipedia.org/wiki/Logit\n",
    "\"\"\"\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        self.w = np.random.randn(dim, 1) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "        \n",
    "    def predict(self, x, probs=False):\n",
    "        x = x.dot(self.w) + self.b\n",
    "        p = sigmoid(x)\n",
    "        if probs:\n",
    "            return p\n",
    "        return np.array(p > 0.5).astype('int32')\n",
    "        \n",
    "    def fit(self, x, y, iters=1000, lr=0.01):\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перенесите обученные веса модели из пункта 1.3 в новую модель с модифицированным кодом\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убедитесь, что предсказания модели с модифицированными кодом совпадают с предсказаниями\n",
    "# модели из пункта 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 'Обобщение' логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите многоклассовый классификатор. Обучите его на наборе данных ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ансамбль логистических регрессий.</b> Сложность: супергерой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Напишите класс, что инкапсулирует в себе `C` логистических регрессий, \n",
    "где `C` - количество классов. i-ая логистическая регрессия производит \n",
    "бинарную классификацию вида: все остальные классы и i-ый класс.\n",
    "\"\"\"\n",
    "\n",
    "class MulticlassLogisticRegression:\n",
    "    def __init__(self, n_classes, dim):\n",
    "        \"\"\"\n",
    "        n_classes - количество классов\n",
    "        dim - размерность входных данных\n",
    "        \"\"\"\n",
    "        self.n_classes = n_classes\n",
    "        self.models = []\n",
    "        \n",
    "        # Инициализация логистических регрессий для каждого класса\n",
    "        for _ in range(n_classes):\n",
    "            self.models.append(LogisticRegression(dim))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x - numpy массив размерности [N, dim]\n",
    "        Возвращает массив целых чисел размерности [N], где i-ый элемент обозначает номер класса\n",
    "        для i-го экземпляра данных в `x`.\n",
    "        \"\"\"\n",
    "        # Получаем вероятности для каждого класса\n",
    "        probs = np.zeros((x.shape[0], self.n_classes))\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            probs[:, i] = model.predict(x, probs=True).flatten()\n",
    "        \n",
    "        # Возвращаем класс с максимальной вероятностью\n",
    "        return np.argmax(probs, axis=1)\n",
    "    \n",
    "    def fit(self, x, y, iters=1000, lr=0.01):\n",
    "        \"\"\"\n",
    "        x - numpy массив входных данных [N, dim]\n",
    "        y - numpy массив меток классов [N]\n",
    "        iters - количество итераций для обучения\n",
    "        lr - скорость обучения\n",
    "        \"\"\"\n",
    "        for i in range(self.n_classes):\n",
    "            # Для i-го класса создаем бинарные метки: 1 для текущего класса, 0 для всех остальных\n",
    "            y_binary = (y == i).astype(int)\n",
    "            self.models[i].fit(x, y_binary, iters=iters, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Regression Accuracy: 94.67%\n"
     ]
    }
   ],
   "source": [
    "# Создайте и обучите написанный классификатор. Оцените точность модели.\n",
    "# Загрузка данных\n",
    "x_train, y_train, x_test, y_test = load_data('dataset3')\n",
    "\n",
    "# Определение количества классов на основе уникальных значений в y_train\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "# Создание и обучение модели\n",
    "model = MulticlassLogisticRegression(n_classes, x_train.shape[1])\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Оценка точности модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Multiclass Logistic Regression Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Инициализация: В конструкторе MulticlassLogisticRegression создается по одному экземпляру логистической регрессии для каждого класса. Все модели обучаются независимо.\n",
    "2. Обучение: Для каждого класса мы создаем бинарные метки, где метка класса равна 1, а все остальные метки равны 0. Таким образом, каждая логистическая регрессия обучается на задаче \"один против всех\".\n",
    "3. Предсказание: Для каждого экземпляра данных мы получаем вероятность от каждой модели и выбираем класс с наибольшей вероятностью.\n",
    "4. Оценка: Используем метрику точности для оценки качества модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Softmax классификатор.</b> Сложность: математический гений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Напишите класс классификатора, основанного на функции Softmax.\n",
    "Алгоритм работы данного классификатора:\n",
    "x - вектор (экземпляр данных) размерности dim.\n",
    "W - матрица весов размерности [dim, n_classes].\n",
    "\n",
    "Ответ классификатора формируется как:\n",
    "logits = x * W - матричное умножение\n",
    "p = softmax(logits)\n",
    "class_id = argmax(p)\n",
    "\n",
    "Для данного классификатора требуется модифицировать алгоритм обучения в методе fit.\n",
    "\n",
    "Вспомогательные ресурсы:\n",
    "https://en.wikipedia.org/wiki/Softmax_function\n",
    "https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/\n",
    "\"\"\"\n",
    "\n",
    "class SoftmaxClassificator:\n",
    "    def __init__(self, n_classes, dim):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Возвращается массив целых чисел размерности [N],\n",
    "        # где i-ый элемент обозначает номер класса для \n",
    "        # i-го экземпляра данных в `x`.\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор. Оцените точность модели, посчитайте матрицу ошибок (выведите её с помощью matplotlib).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор на наборе данных из задания 1 (опционально). \n",
    "# Оцените точность модели, посчитайте матрицу ошибок (выведите её с помощью matplotlib).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
